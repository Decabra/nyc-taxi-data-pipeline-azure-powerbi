{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe339033-0089-4b67-b1d8-a38f74580397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in c:\\users\\sarma\\anaconda3\\lib\\site-packages (12.25.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-storage-blob) (1.34.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-storage-blob) (43.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-storage-blob) (4.11.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-storage-blob) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-storage-blob) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarma\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fa4f8-6902-4a2a-bf0b-b45b5b6c6307",
   "metadata": {},
   "source": [
    "We will upload the parquet file to Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d2c89f-8f3d-4fa8-b16e-3cb3d45185ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "class ProgressReader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file = open(file_path, 'rb')\n",
    "        self.size = os.path.getsize(file_path)\n",
    "        self.read_bytes = 0\n",
    "\n",
    "    def read(self, chunk_size):\n",
    "        chunk = self.file.read(chunk_size)\n",
    "        if chunk:\n",
    "            self.read_bytes += len(chunk)\n",
    "            percent = (self.read_bytes / self.size) * 100\n",
    "            sys.stdout.write(f\"\\rUploading... {percent:.2f}%\")\n",
    "            sys.stdout.flush()\n",
    "        return chunk\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a441b51-a661-40c2-8333-b70ccbadff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/sarma/Power BI/NYC Yellow Taxi/dataset\"\n",
    "files_2024 = glob.glob(os.path.join(folder_path, 'yellow_tripdata_2024-*.parquet'))\n",
    "files_2023 = glob.glob(os.path.join(folder_path, 'yellow_tripdata_2023-*.parquet'))\n",
    "df_2023 = pd.concat([pd.read_parquet(file) for file in files_2023])\n",
    "df_2024 = pd.concat([pd.read_parquet(file) for file in files_2024])\n",
    "# Merge airport fee columns based on which one has the values\n",
    "df_2023['Airport_fee'] = df_2023['airport_fee'].combine_first(df_2023['Airport_fee'])\n",
    "# Lets drop the extra airport fee column\n",
    "df_2023.drop(columns = ['airport_fee'],  inplace=True)\n",
    "final_df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "columns = [\n",
    "    'tpep_pickup_datetime', # The date and time when the meter was engaged.\n",
    "    'tpep_dropoff_datetime', # The date and time when the meter was disengaged.\n",
    "    'passenger_count', # The number of passengers in the vehicle.\n",
    "    'trip_distance', # The elapsed trip distance in miles reported by the taximeter.\n",
    "    'PULocationID', # TLC Taxi Zone in which the taximeter was engaged\n",
    "    'DOLocationID', # TLC Taxi Zone in which the taximeter was disengaged\n",
    "    'payment_type', # 0 = Flex Fare trip 1 = Credit card 2 = Cash 3 = No charge 4 = Dispute 5 = Unknown 6 = Voided trip\n",
    "    'fare_amount', # The time-and-distance fare calculated by the meter.\n",
    "    'extra', # Miscellaneous extras and surcharges.\n",
    "    'mta_tax', # Tax that is automatically triggered based on the metered rate in use.\n",
    "    'tip_amount', # Tip amount – This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "    'tolls_amount', # Total amount of all tolls paid in trip.\n",
    "    'total_amount', # The total amount charged to passengers. Does not include cash tips.\n",
    "    'congestion_surcharge', # Total amount collected in trip for NYS congestion surcharge.\n",
    "    'Airport_fee', # For pick up only at LaGuardia and John F. Kennedy Airports.\n",
    "]\n",
    "taxis_df = final_df[columns]\n",
    "# Lets create a record_id to match with our SQL table\n",
    "taxis_df = taxis_df.copy() # Fix copy of a slice warning from pandas\n",
    "taxis_df.reset_index(drop=True, inplace=True)\n",
    "taxis_df['record_id'] = taxis_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789755d-7b47-4227-9e7a-b30f417e7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis_df.to_parquet(\"yellow_taxis_data.parquet\", engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d281e58-99e0-4080-b9e8-24c085718a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as pc\n",
    "\n",
    "# Load Parquet\n",
    "table = pq.read_table(\"yellow_taxis_data.parquet\")\n",
    "\n",
    "# Write CSV\n",
    "pc.write_csv(table, \"yellow_taxis_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8130bc7-ed47-4bb3-bb8f-4af7df6cf578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading... 100.00%Upload complete ✅\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContentSettings\n",
    "\n",
    "# Credentials\n",
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=msazureblob;AccountKey=qAht80J++08DlOpG7rwY6L9ufwlVT7CyGDUaZm8jjjqhv0q//k7NgtdzvOkDW044cIAHgV6pzGNJ+AStiwuO7A==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"taxis-data-container\"\n",
    "blob_name = \"yellow-taxis.csv\"\n",
    "local_file_path = \"C:/Users/sarma/Power BI/NYC Yellow Taxi/yellow_taxis_data.csv\"\n",
    "\n",
    "# Create client \n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "reader = ProgressReader(local_file_path)\n",
    "with open(local_file_path, \"rb\") as data:\n",
    "    blob_client.upload_blob( \n",
    "        data=reader,\n",
    "        blob_type=\"BlockBlob\",\n",
    "        overwrite=True,\n",
    "        max_concurrency=16,  # Increase this if you have good CPU + network\n",
    "        content_settings=ContentSettings(content_type='text/csv')\n",
    "    )\n",
    "\n",
    "reader.close()\n",
    "print(\"\\nUpload complete ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ae7e9-93cf-445c-9f5c-f58670a697d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet\n",
    "blob_sas_token = \"sp=r&st=2025-05-29T19:57:20Z&se=2025-05-30T03:57:20Z&spr=https&sv=2024-11-04&sr=b&sig=FP1Gs9t4rJeuDyghfKWbHCd82aIc7koGKwh%2F6S%2BjfX0%3D\"\n",
    "blob_sas_url = \"https://msazureblob.blob.core.windows.net/taxis-data-container/yellow-taxis-data?sp=r&st=2025-05-29T19:57:20Z&se=2025-05-30T03:57:20Z&spr=https&sv=2024-11-04&sr=b&sig=FP1Gs9t4rJeuDyghfKWbHCd82aIc7koGKwh%2F6S%2BjfX0%3D\"\n",
    "# CSV\n",
    "blob_sas_token = \"sp=r&st=2025-05-29T21:35:08Z&se=2025-05-30T05:35:08Z&spr=https&sv=2024-11-04&sr=b&sig=CYzATqCUwqWaXMbg%2BKEOFOk2hnUdfoSf3dhL9kQNtTY%3D\"\n",
    "blob_sas_url = \"https://msazureblob.blob.core.windows.net/taxis-data-container/yellow-taxis-csv?sp=r&st=2025-05-29T21:35:08Z&se=2025-05-30T05:35:08Z&spr=https&sv=2024-11-04&sr=b&sig=CYzATqCUwqWaXMbg%2BKEOFOk2hnUdfoSf3dhL9kQNtTY%3D\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
